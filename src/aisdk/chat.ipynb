{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a copilot using Azure AI Studio\n",
    "\n",
    "In this tutorial, you will learn how to build, run, and evaluate, a copilot application using your own custom data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1 | Pre-Work: Setup AI Project**\n",
    "\n",
    "Before opening this Notebook, we assume you already completed the following steps:\n",
    "\n",
    "1. [Step 1](./../docs/step-01.md) - setup your development environment.\n",
    "1. [Step 2](./../docs/step-02.md) - run `ai init` to create AI project\n",
    "1. [Step 3a](./../docs/step-03.md) - run `ai search` to create Search index\n",
    "1. [Step 3b](./../docs/step-03.md) - run `ai dev new .env` to save env vars.\n",
    "\n",
    "ðŸŽ‰ _Congratulations!_ - You are now ready to start working with the Azure AI Studio SDK to interact with your Azure AI resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 | Setup: Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables (from .env)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 | Define: Azure AI Search Helper Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Function 1 => GET INDEXED DOCUMENTS FOR QUERY\n",
    "## Given a query (question)and a desired number of documents (default=5)\n",
    "## Retrieve the relevant set of matching results for the query from Cognitive Search\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.models import RawVectorQuery\n",
    "\n",
    "async def get_documents(query, num_docs=5):\n",
    "\n",
    "    #  retrieve documents relevant to the user's question from Cognitive Search\n",
    "    search_client = SearchClient(\n",
    "        endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"],\n",
    "        credential=AzureKeyCredential(os.environ[\"AZURE_AI_SEARCH_KEY\"]),\n",
    "        index_name=os.environ[\"AZURE_AI_SEARCH_INDEX_NAME\"])\n",
    "\n",
    "    # generate a vector embedding of the user's question\n",
    "    embedding = await openai.Embedding.acreate(input=query,\n",
    "                                               model=os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "                                               deployment_id=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"])\n",
    "    embedding_to_query = embedding[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # initialize context, then update it with results from query\n",
    "    context = \"\"\n",
    "    async with search_client:\n",
    "\n",
    "        # use the vector embedding to do a vector search on the index\n",
    "        vector_query = RawVectorQuery(vector=embedding_to_query, k=num_docs, fields=\"contentVector\")\n",
    "        results = await search_client.search(\n",
    "            search_text=\"\",\n",
    "            vector_queries=[vector_query],\n",
    "            select=[\"id\", \"content\"])\n",
    "\n",
    "        async for result in results:\n",
    "            context += f\"\\n>>> From: {result['id']}\\n{result['content']}\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4 | Define Azure OpenAI ChatCompletion Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TemplateNotFound",
     "evalue": "system-message.jinja2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTemplateNotFound\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m templateLoader \u001b[39m=\u001b[39m jinja2\u001b[39m.\u001b[39mFileSystemLoader(searchpath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./../\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m templateEnv \u001b[39m=\u001b[39m jinja2\u001b[39m.\u001b[39mEnvironment(loader\u001b[39m=\u001b[39mtemplateLoader)\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m system_message_template \u001b[39m=\u001b[39m templateEnv\u001b[39m.\u001b[39;49mget_template(\u001b[39m\"\u001b[39;49m\u001b[39msystem-message.jinja2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mchat_completion\u001b[39m(messages: \u001b[39mlist\u001b[39m[\u001b[39mdict\u001b[39m], stream: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                           session_state: \u001b[39many\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, context: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39many\u001b[39m] \u001b[39m=\u001b[39m {}):\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# get search documents for the last user message in the conversation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c65222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6e697479612f4769744875622f617a7572652d73616d706c65732f616973747564696f2d707974686f6e2d717569636b73746172742d73616d706c652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/aistudio-python-quickstart-sample/src/aisdk/chat.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     user_message \u001b[39m=\u001b[39m messages[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jinja2/environment.py:1010\u001b[0m, in \u001b[0;36mEnvironment.get_template\u001b[0;34m(self, name, parent, globals)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[39mif\u001b[39;00m parent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_path(name, parent)\n\u001b[0;32m-> 1010\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_template(name, \u001b[39mglobals\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jinja2/environment.py:969\u001b[0m, in \u001b[0;36mEnvironment._load_template\u001b[0;34m(self, name, globals)\u001b[0m\n\u001b[1;32m    965\u001b[0m             template\u001b[39m.\u001b[39mglobals\u001b[39m.\u001b[39mupdate(\u001b[39mglobals\u001b[39m)\n\u001b[1;32m    967\u001b[0m         \u001b[39mreturn\u001b[39;00m template\n\u001b[0;32m--> 969\u001b[0m template \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m, name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_globals(\u001b[39mglobals\u001b[39;49m))\n\u001b[1;32m    971\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache[cache_key] \u001b[39m=\u001b[39m template\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jinja2/loaders.py:126\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self, environment, name, globals)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[39mglobals\u001b[39m \u001b[39m=\u001b[39m {}\n\u001b[1;32m    124\u001b[0m \u001b[39m# first we try to get the source for this template together\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m# with the filename and the uptodate function.\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m source, filename, uptodate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_source(environment, name)\n\u001b[1;32m    128\u001b[0m \u001b[39m# try to load the code from the bytecode cache if there is a\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m# bytecode cache configured.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m bcc \u001b[39m=\u001b[39m environment\u001b[39m.\u001b[39mbytecode_cache\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jinja2/loaders.py:218\u001b[0m, in \u001b[0;36mFileSystemLoader.get_source\u001b[0;34m(self, environment, template)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# Use normpath to convert Windows altsep to sep.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m contents, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mnormpath(filename), uptodate\n\u001b[0;32m--> 218\u001b[0m \u001b[39mraise\u001b[39;00m TemplateNotFound(template)\n",
      "\u001b[0;31mTemplateNotFound\u001b[0m: system-message.jinja2"
     ]
    }
   ],
   "source": [
    "## Helper Function 2 => GET CHAT COMPLETION MESSAGES\n",
    "## Given a list of user messages, a streaming flag, session state and context\n",
    "##    Call get_documents to get 5 relevant results matching the user question\n",
    "##    Make copy of context and modify to add retrieved documents\n",
    "##    Add retrieved documents to the system prompt section\n",
    "##    Call Azure OpenAI with the system prompt and user question\n",
    "\n",
    "import jinja2\n",
    "import pathlib\n",
    "\n",
    "from streaming_utils import add_context_to_streamed_response\n",
    "\n",
    "templateLoader = jinja2.FileSystemLoader(searchpath=\"./\")\n",
    "templateEnv = jinja2.Environment(loader=templateLoader)\n",
    "system_message_template = templateEnv.get_template(\"system-message.jinja2\")\n",
    "\n",
    "async def chat_completion(messages: list[dict], stream: bool = False,\n",
    "                          session_state: any = None, context: dict[str, any] = {}):\n",
    "    # get search documents for the last user message in the conversation\n",
    "    user_message = messages[-1][\"content\"]\n",
    "    documents = await get_documents(user_message, context.get(\"num_retrieved_docs\", 5))\n",
    "\n",
    "    # make a copy of the context and modify it with the retrieved documents\n",
    "    context = dict(context)\n",
    "    context['documents'] = documents\n",
    "\n",
    "    # add retrieved documents as context to the system prompt\n",
    "    system_message = system_message_template.render(context=context)\n",
    "    messages.insert(0, {\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    # call Azure OpenAI with the system prompt and user's question\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "        messages=messages, temperature=context.get(\"temperature\", 0.7),\n",
    "        stream=stream,\n",
    "        max_tokens=800)\n",
    "\n",
    "    # add context in the returned response\n",
    "    if not stream:\n",
    "        response.choices[0]['context'] = context\n",
    "    else:\n",
    "        response = add_context_to_streamed_response(response, context)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 | Invoke the Chat Completion Endpoint with the User Question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation = \"aisdk\"  (default only)\n",
    "# For now just invoke the method in the default python script.\n",
    "from chat import chat_completion\n",
    "\n",
    "# Simple question test\n",
    "question = \"Which tent is the most waterproof?\"\n",
    "\n",
    "# Define an async function to call the chat function\n",
    "result = await chat_completion([{\"role\": \"user\", \"content\": question}], stream=False)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
